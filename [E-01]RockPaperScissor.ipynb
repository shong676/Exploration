{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24729762",
   "metadata": {},
   "source": [
    "# 1조 홍성진 Expoloration_01_Rock_Scissor_Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1e26165",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from PIL import Image\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d910c8fe",
   "metadata": {},
   "source": [
    "## Resize image 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba1196e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#resize images 정의\n",
    "def resize_images(img_path):\n",
    "    images = glob.glob(img_path + \"\\*.jpg\")\n",
    "    \n",
    "    print(len(images), \" images to be resized\")\n",
    "    \n",
    "    #파일마다 28x28사이즈로 변경 후 저장\n",
    "    target_size = (28,28)\n",
    "    for img in images:\n",
    "        old_img = Image.open(img)\n",
    "        new_img = old_img.resize(target_size,Image.ANTIALIAS)\n",
    "        new_img.save(img, \"JPEG\")\n",
    "        \n",
    "    print(len(images)), \"images resized.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18870c02",
   "metadata": {},
   "source": [
    "## Resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70adcbdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "679  images to be resized\n",
      "679\n",
      "가위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "#가위 이미지가 저장 된 디렉토리 아래의 모든 jpg 파일 읽어서 resize\n",
    "image_dir_path = os.getenv(\"USERPROFILE\") + \"\\\\Self_Study\\\\LMS\\\\Exp\\\\Ex_1\\\\rock_scissor_paper\\\\scissor\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"가위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "525d310e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "860  images to be resized\n",
      "860\n",
      "바위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "#바위 이미지가 저장 된 디렉토리 아래의 모든 jpg 파일 읽어서 resize\n",
    "image_dir_path = os.getenv(\"USERPROFILE\") + \"\\\\Self_Study\\\\LMS\\\\Exp\\\\Ex_1\\\\rock_scissor_paper\\\\rock\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"바위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1f961c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "757  images to be resized\n",
      "757\n",
      "보 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "#보 이미지가 저장 된 디렉토리 아래의 모든 jpg 파일 읽어서 resize\n",
    "image_dir_path = os.getenv(\"USERPROFILE\") + \"\\\\Self_Study\\\\LMS\\\\Exp\\\\Ex_1\\\\rock_scissor_paper\\\\paper\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"보 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f1390c",
   "metadata": {},
   "source": [
    "## 가위,바위,보 데이터를 읽을 수 있는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "355af30d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 2296 입니다.\n",
      "x_train shape: (2296, 28, 28, 3)\n",
      "y_train shape: (2296,)\n"
     ]
    }
   ],
   "source": [
    "#가위,바위,보 데이터를 읽을 수 있는 함수\n",
    "import numpy as np\n",
    "\n",
    "def load_data(img_path, number_of_data = 2296): #가위바위보 이미지 개수 총 합 (350x3)\n",
    "    #가위: 0, 바위: 1, 보: 2\n",
    "    img_size = 28 # 28x28\n",
    "    color = 3  #1이면 흑백, 3이면 칼라\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs = np.zeros(number_of_data*img_size*img_size*color, dtype = np.int32).reshape(number_of_data, img_size, img_size, color)\n",
    "    #imgs = 0행렬(총이미지합 x 이미지사이즈 x 이미지사이즈 x 색깔, 데이터 타입 = 32비트 정수). 생긴거는, 이미지 총합, nxn , 색유무\n",
    "    \n",
    "    labels = np.zeros(number_of_data, dtype=np.int32)\n",
    "    #라벨링 = 이미지 총합, 32비트 정수\n",
    "    \n",
    "    idx = 0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype = np.int32)\n",
    "        imgs[idx,:,:,:] = img #데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0 #가위: 0\n",
    "        idx += 1\n",
    "       \n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype = np.int32)\n",
    "        imgs[idx,:,:,:] = img #데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1 #바위: 1\n",
    "        idx += 1\n",
    "        \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype = np.int32)\n",
    "        imgs[idx,:,:,:] = img #데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2 #보: 2\n",
    "        idx +=1\n",
    "    \n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\", idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"USERPROFILE\") + \"/Self_Study/LMS/Exp/Ex_1/rock_scissor_paper\"\n",
    "(x_train, y_train) = load_data(image_dir_path)\n",
    "x_train_norm = x_train/255.0 #입력은 0~1사이의 값으로 정규화\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_train_norm.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4caf65",
   "metadata": {},
   "source": [
    "## 이미지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1366e88e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라벨:  0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "nn=102\n",
    "plt.imshow(x_train_norm[nn])\n",
    "print('라벨: ',y_train[nn])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89824305",
   "metadata": {},
   "source": [
    "# 딥러닝 네트워크 설계하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "88158c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_4 (Conv2D)           (None, 26, 26, 64)        1792      \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 13, 13, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 11, 11, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 5, 5, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 3200)              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 16)                51216     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 3)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 126,915\n",
      "Trainable params: 126,915\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(64, (3,3), activation = 'relu', input_shape = (28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(128, (3,3), activation = 'relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(16, activation = 'relu'))\n",
    "model.add(keras.layers.Dense(3, activation = 'softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74aee1ca",
   "metadata": {},
   "source": [
    "# 딥러닝 네트워크 학습시키기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a0cdf6f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Befroe Reshape - x_train_norm shape: (2296, 28, 28, 3)\n",
      "Epoch 1/5\n",
      "72/72 [==============================] - 2s 18ms/step - loss: 0.6954 - accuracy: 0.7030\n",
      "Epoch 2/5\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.1755 - accuracy: 0.9538\n",
      "Epoch 3/5\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0649 - accuracy: 0.9861\n",
      "Epoch 4/5\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0365 - accuracy: 0.9922\n",
      "Epoch 5/5\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0187 - accuracy: 0.9978\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1eabeeb6fd0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Befroe Reshape - x_train_norm shape: {}\".format(x_train_norm.shape))\n",
    "\n",
    "model.compile(optimizer = 'adam',\n",
    "              loss = 'sparse_categorical_crossentropy',\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "model.fit(x_train_norm, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d815af",
   "metadata": {},
   "source": [
    "# 얼마나 잘 만들었는지 (테스트)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc005ca1",
   "metadata": {},
   "source": [
    "### 가위 test이미지 resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e02c1d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106  images to be resized\n",
      "106\n",
      "가위 Test이미지 rezise 완료!\n"
     ]
    }
   ],
   "source": [
    "image_dir_path = os.getenv(\"USERPROFILE\") + \"\\\\Self_Study\\\\LMS\\\\Exp\\\\Ex_1\\\\rock_scissor_paper\\\\test\\\\scissor\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"가위 Test이미지 rezise 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4a9fff",
   "metadata": {},
   "source": [
    "### 바위 test이미지 resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "22339582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114  images to be resized\n",
      "114\n",
      "바위 Test이미지 rezise 완료!\n"
     ]
    }
   ],
   "source": [
    "image_dir_path = os.getenv(\"USERPROFILE\") + \"\\\\Self_Study\\\\LMS\\\\Exp\\\\Ex_1\\\\rock_scissor_paper\\\\test\\\\rock\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"바위 Test이미지 rezise 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469d371e",
   "metadata": {},
   "source": [
    "### 보 test이미지 resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8222a624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99  images to be resized\n",
      "99\n",
      "보 Test이미지 rezise 완료!\n"
     ]
    }
   ],
   "source": [
    "image_dir_path = os.getenv(\"USERPROFILE\") + \"\\\\Self_Study\\\\LMS\\\\Exp\\\\Ex_1\\\\rock_scissor_paper\\\\test\\\\paper\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"보 Test이미지 rezise 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d52c4f1",
   "metadata": {},
   "source": [
    "# Test이미지 데이터를 읽을 수 있는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f493f13",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_test)의 이미지 개수는 319 입니다.\n",
      "x_test shape: (319, 28, 28, 3)\n",
      "y_test shape: (319,)\n"
     ]
    }
   ],
   "source": [
    "def load_data(img_path, number_of_data=319):  # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1  \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_test)의 이미지 개수는\", idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"USERPROFILE\") + \"\\\\Self_Study\\\\LMS\\\\Exp\\\\Ex_1\\\\rock_scissor_paper\\\\test\"\n",
    "(x_test, y_test)=load_data(image_dir_path)\n",
    "x_test_norm = x_test/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_test shape: {}\".format(x_test_norm.shape))\n",
    "print(\"y_test shape: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2ad5e6d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라벨:  0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "nn=102\n",
    "plt.imshow(x_test[nn])\n",
    "print('라벨: ',y_test[nn])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42df20b",
   "metadata": {},
   "source": [
    "## Test accuracy 측정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8f7467e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 0s - loss: 0.7636 - accuracy: 0.9875 - 131ms/epoch - 13ms/step\n",
      "test_loss: 0.7636111974716187 \n",
      "test_accuracy: 0.9874607920646667\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(x_test,y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03348dc",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c928793e",
   "metadata": {},
   "source": [
    "# 회고"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cdbcb8e",
   "metadata": {},
   "source": [
    "첫 번째 Exploration을 하고, 상상으로만 했던 인공지능 구동 매커니즘에 대해 전체적인 흐름을 알 수있어 매우 흥미로웠습니다.\n",
    "\n",
    "  프로젝트를 진행하며, 인식률을 높히기 위해 많은 시도를 하였지만, 제가 새운 가설과 결과가 맞아 떨어지지 않을 때가 가장 어려웠습니다.<br>\n",
    "  \n",
    "  첫 가설은, 다양한 생김세의 가위바위보 샘플 테이터들이 있다면, 이를 다양하게 학습하여 어떠한 테스트 데이터도 인식 할 수있지 않을까 하는 가설이었습니다. 때문에 혼자서도 다양한 각도로 샘플을 수집해 보았고, 또한 같은 조원들의 샘플 데이터까지도 모아 학습 해 보았습니다. 하지만, 다양한 샘플데이터를 담기에는, 고작 몇 천장 정도로는 부족할 것이며, 그 외에도 같은 방의 환경, 뚜렷하지 않은 이미지, 최대 6명뿐의 손 등 학습시키기 좋지 않은 조건들을 발견하여 제 가설을 제대로 실천 할 수 없는 환경이라는 것을 깨달았습니다.<br>\n",
    "  \n",
    "  그렇게 세운 두 번째 가설은, Exploration 1-3에서 나왔듯, tf.keras의 Sequential API를 이용하여 LeNet이라는 딥러닝 네트워크 설계한 부분을 건드려 보는 것이었습니다. 우선, 나와있는 부분들인, Conv2D, Dense 부분에 대하여는 설명이 쓰여있어서, 얼마나 다양한 특징을 살펴볼지, 얼마나 복잡한 알고리즘을 사용할 것인지를 건드려 보았습니다. 사실 이 부분에 관하여서도 정확하게 어떤 특징을 잡는것인지, 복잡한 문제라는것은 어떤 의미인지를 잘 몰랐지만, 최저 16부터, 최대 1024까지 다양하게 조절해 보았습니다. 처음에는 숫자가 높을수록 무조건 유리한게 아닐까? 라는 가설을 세웠었지만, 너무높아도, 너무 낮아도 안된다는 사실을 알게되었습니다. 그 외에, Maxpool은 무엇인지, (2,2)는 무엇을 의미하는 것인지에 대해 조사를 해 보았습니다. 몇 곂의 뉴런을 이용할 것인지 라는 간략한 이야기 외에 깊은 내용을 이해하지 못하여서 큰 값을 만져보지는 못하였습니다. 또한 activation은 어떤 것을 바꿀 수 있을까에 대하여도 궁금하여, 조사하였더니, \"rule\", \"sigmond\", \"softmax\" 라는 것이 있다는것을 알게되었고, 이를 통하여 LeNet 네트워크로 다른 분류문제를 이용할 수도 있갰구나 하고 알게되었습니다. 이렇게 모든 변수들을 조정하여 보았지만, 저의 인식률을 크게 나아지지 않았기에, 최적의 네트워크 값은 넣되, 다른 가설을 또 세워봐야 겠다고 생각하였습니다.<br>\n",
    "  \n",
    "  그렇게 세운 세 번째 가설은, 정직하고 정확한 이미지 데이터를 학습시키는 것 이었습니다. 제가 학습시켰던 모든 학습용 데이터 중 사람얼굴이 곂치거나, 손의 이미지가 명확하지 않거나, 사람이 보아도 가위인지 바위인지, 보인지 구분 할 수 없는 이미지들은 모두 지워냈고, 또한 검정 배경에 하얀 손이 보이게끔 다양한 학습데이터를 다시 수집하였습니다. 이 세 번쨰 가설이 가장 눈에 띄는 결과를 나타내었지만, accracy 60%를 겨우 넘길 뿐, 최대 70% 이상은 나오지 않았습니다. 이에 만족할 수 없었던 저는, 마지막 가설을 세웠습니다.<br>\n",
    "  \n",
    "  마지막 네 번째 가설은 테스트 데이터이미지 까지 정직하고 정확한 이미지 데이터로 학습시키는 것 이었습니다. 위의 세 번째 가설에서 했듯, 명확하지 않은 데이터는 모두 삭제하고, 다른 데이터가 필요했던 저는, 저의 손으로 하면 학습용 데이터와 너무 비슷할 것 같아 제 3자인, 친구에게 부탁하여 새로운 이미지 데이터를 수집하였습니다. 결국 그렇게 정확한 이미지 데이터로 학습을 시키고, 정확한 이미지 데이터로 테스트를 해 본 결과, 어떻게 시도를 하여도 accuracy 90%를 넘는 뛰어난 결과를 얻게 되었습니다.<br>\n",
    "  \n",
    "  이로써, 인식률을 높이는데에 관하여 다양한 방법을 알아보았고, 이를 직관적으로 확인할 수 있었습니다. 60%에서 만족할뻔한 제 자신에서 결국 90%를 넘는 이 프로젝트에 매우 만족하였으며, 자신감이 좀 더 생겼습니다.<br>\n",
    "  이 외에도 학습시에 accracy가 1이 넘는값이 지속되면 오버피팅 하다 생각이 들어, epochs의 값을 조정하여 다양하게 학습 해 보았습니다.<br>\n",
    "\n",
    "\n",
    "요약하여,\n",
    "- 이번 프로젝트에선 인식률을 높히기 위한 나의 노력이 큰 결과를 보이지 못하였을 떄 가장 어려웠습니다.\n",
    "- 그 인식률을 높히기 위하여 다양하게 공부하고 시도한 부분에서 Maxpool이 무엇인지, activation의 다른종류가 있는지, 학습용, 테스트용 데이터의 질이 얼마나 중요한지를 알아내었습니다.\n",
    "- 하지만 아직 maxpool(2,2) 값에 대한 부분 등, LeNet을 조정하는 부분에 관하여 모호합니다.\n",
    "- 루브릭 평가 지표를 맞추기 위해 시도한 것들로는, 데이터를 다양하게 모아보고, LeNet 네트워크의 변수를 수정해 보았고, 학습데이터를 질이 좋은 데이터로만도 사용해 보았고, 테스트 데이터의 질을 높혀보기도 하였습니다. 마지막으로는 오버피팅 되지 않게 하기위해,  epochs값을 조정하여 적당한 반복값을 찾아보기도 하였습니다.\n",
    "- 만약 루브릭 평가 지표를 달설하지 못하였다면 이번 강의의 세세한 부분까지 캐치하지 못했다고 생각하여 다시한번 분석하고 제가 스스로 바꿔볼 수 있는 변수들은 모두 바꾸어 보았을겁니다.\n",
    "<br>\n",
    "앞으로의 다짐은, 제가 생각했던 인공지능과는 생각보다 다른부분에 대해 만족스럽지 못한 결과를 얻었던 것 같습니다. 때문에 앞으로의 공부에서도 조금 더 깊게 공부하여 어떤부분에서 왜 잘못되었는지를 명확하게 알 수 있게끔 알아 볼 예정이며 후에 지식이 쌓였을 떄에는, 저의 가설이 바로 통할 수 있게끔 방대한 지식을 갖게끔 할 것입니다.\n",
    "\n",
    "감사합니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
