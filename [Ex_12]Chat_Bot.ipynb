{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f3112d6",
   "metadata": {},
   "source": [
    "# EXPLORATION 12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956ddbfa",
   "metadata": {},
   "source": [
    "## Step 1. 데이터 수집하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ac72e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90006506",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "path_to_dataset = os.getenv(\"HOME\")+\"/aiffel/transformer_chatbot/data/ChatbotData.csv\"\n",
    "\n",
    "read = pd.read_csv(path_to_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0fd27c0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12시 땡!</td>\n",
       "      <td>하루가 또 가네요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3박4일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3박4일 정도 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPL 심하네</td>\n",
       "      <td>눈살이 찌푸려지죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SD카드 망가졌어</td>\n",
       "      <td>다시 새로 사는 게 마음 편해요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SD카드 안돼</td>\n",
       "      <td>다시 새로 사는 게 마음 편해요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SNS 맞팔 왜 안하지ㅠㅠ</td>\n",
       "      <td>잘 모르고 있을 수도 있어요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SNS 시간낭비인 거 아는데 매일 하는 중</td>\n",
       "      <td>시간을 정하고 해보세요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SNS 시간낭비인데 자꾸 보게됨</td>\n",
       "      <td>시간을 정하고 해보세요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Q                   A  label\n",
       "0                   12시 땡!          하루가 또 가네요.      0\n",
       "1              1지망 학교 떨어졌어           위로해 드립니다.      0\n",
       "2             3박4일 놀러가고 싶다         여행은 언제나 좋죠.      0\n",
       "3          3박4일 정도 놀러가고 싶다         여행은 언제나 좋죠.      0\n",
       "4                  PPL 심하네          눈살이 찌푸려지죠.      0\n",
       "5                SD카드 망가졌어  다시 새로 사는 게 마음 편해요.      0\n",
       "6                  SD카드 안돼  다시 새로 사는 게 마음 편해요.      0\n",
       "7           SNS 맞팔 왜 안하지ㅠㅠ    잘 모르고 있을 수도 있어요.      0\n",
       "8  SNS 시간낭비인 거 아는데 매일 하는 중       시간을 정하고 해보세요.      0\n",
       "9        SNS 시간낭비인데 자꾸 보게됨       시간을 정하고 해보세요.      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = read[0:10]\n",
    "len(read)\n",
    "data.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ce4fd6",
   "metadata": {},
   "source": [
    "## Step 2. 데이터 전처리하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9e3af9",
   "metadata": {},
   "source": [
    "SOYNLP를 이용한 단어 토큰화를 하였습니다.\n",
    "출처:https://wikidocs.net/92961"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41963490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: soynlp in /opt/conda/lib/python3.9/site-packages (0.0.493)\n",
      "Requirement already satisfied: numpy>=1.12.1 in /opt/conda/lib/python3.9/site-packages (from soynlp) (1.21.4)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.9/site-packages (from soynlp) (1.7.1)\n",
      "Requirement already satisfied: psutil>=5.0.1 in /opt/conda/lib/python3.9/site-packages (from soynlp) (5.8.0)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /opt/conda/lib/python3.9/site-packages (from soynlp) (1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.9/site-packages (from scikit-learn>=0.20.0->soynlp) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.9/site-packages (from scikit-learn>=0.20.0->soynlp) (3.0.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install soynlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21aec42f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['12시', '땡', '!']\n",
      "['1', '지망', '학교', '떨어졌어']\n",
      "['3', '박', '4일', '놀러', '가고', '싶다']\n",
      "['3', '박', '4일', '정도', '놀러', '가고', '싶다']\n",
      "['PPL', '심하네']\n",
      "['SD', '카드', '망가졌어']\n",
      "['SD', '카드', '안', '돼']\n",
      "['SNS', '맞팔', '왜', '안', '하지', 'ㅠㅠ']\n",
      "['SNS', '시간', '낭비', '인', '거', '아는데', '매일', '하는', '중']\n",
      "['SNS', '시간', '낭비', '인데', '자꾸', '보게', '됨']\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Okt\n",
    "tokenizer = Okt()\n",
    "for i in range(10):\n",
    "    print(tokenizer.morphs(read[\"Q\"][i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f211af66",
   "metadata": {},
   "source": [
    "데이터 개수 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d69b792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 수:  11823\n",
      "전체 샘플 수:  11823\n"
     ]
    }
   ],
   "source": [
    "questions_list = []\n",
    "answers_list = []\n",
    "for i in range(len(read)):\n",
    "    questions_list.append(tokenizer.morphs(read[\"Q\"][i]))\n",
    "    answers_list.append(tokenizer.morphs(read[\"A\"][i]))\n",
    "\n",
    "print(\"전체 샘플 수: \",len(questions_list))\n",
    "print(\"전체 샘플 수: \",len(answers_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "472d57d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12시 땡 !\n",
      "하루 가 또 가네요 .\n",
      "==========\n",
      "1 지망 학교 떨어졌어\n",
      "위로 해 드립니다 .\n",
      "==========\n",
      "3 박 4일 놀러 가고 싶다\n",
      "여행 은 언제나 좋죠 .\n",
      "==========\n",
      "3 박 4일 정도 놀러 가고 싶다\n",
      "여행 은 언제나 좋죠 .\n",
      "==========\n",
      "PPL 심하네\n",
      "눈살 이 찌푸려지죠 .\n",
      "==========\n",
      "SD 카드 망가졌어\n",
      "다시 새로 사는 게 마음 편해요 .\n",
      "==========\n",
      "SD 카드 안 돼\n",
      "다시 새로 사는 게 마음 편해요 .\n",
      "==========\n",
      "SNS 맞팔 왜 안 하지 ㅠㅠ\n",
      "잘 모르고 있을 수도 있어요 .\n",
      "==========\n",
      "SNS 시간 낭비 인 거 아는데 매일 하는 중\n",
      "시간 을 정 하고 해보세요 .\n",
      "==========\n",
      "SNS 시간 낭비 인데 자꾸 보게 됨\n",
      "시간 을 정 하고 해보세요 .\n",
      "==========\n"
     ]
    }
   ],
   "source": [
    "questions = []\n",
    "answers = []\n",
    "\n",
    "for i in range(len(questions_list)):\n",
    "    q_temp = \"\"\n",
    "    for j in range(len(questions_list[i])-1):\n",
    "        q_temp += questions_list[i][j] + \" \"\n",
    "    q_temp += (questions_list[i][-1])\n",
    "    questions.append(q_temp)\n",
    "    \n",
    "for i in range(len(answers_list)):\n",
    "    a_temp = \"\"\n",
    "    for j in range(len(answers_list[i])-1):\n",
    "        a_temp += answers_list[i][j] + \" \"\n",
    "    a_temp += (answers_list[i][-1])\n",
    "    answers.append(a_temp)\n",
    "\n",
    "        \n",
    "\n",
    "for i in range(10):\n",
    "    print(questions[i])\n",
    "    print(answers[i])\n",
    "    print(\"=\"*10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df8983c",
   "metadata": {},
   "source": [
    "## Step 3. SubwordTextEncoder 사용하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3192fadd",
   "metadata": {},
   "source": [
    "한국어 데이터는 형태소 분석기를 사용하여 토크나이징을 해야 한다고 많은 분이 알고 있습니다. 하지만 여기서는 형태소 분석기가 아닌 위 실습에서 사용했던 내부 단어 토크나이저인 SubwordTextEncoder를 그대로 사용해보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea72c7de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "살짝 오래 걸릴 수 있어요. 스트레칭 한 번 해볼까요? 👐\n",
      "슝=3 \n"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "print(\"살짝 오래 걸릴 수 있어요. 스트레칭 한 번 해볼까요? 👐\")\n",
    "\n",
    "# 질문과 답변 데이터셋에 대해서 Vocabulary 생성. (Tensorflow 2.3.0 이상) (클라우드는 2.4 입니다)\n",
    "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(questions + answers, target_vocab_size=2**13)\n",
    "print(\"슝=3 \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea1baff",
   "metadata": {},
   "source": [
    "시작토큰과 종료토큰 부여"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77c2b80f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# 시작 토큰과 종료 토큰에 고유한 정수를 부여합니다.\n",
    "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d66b6c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START_TOKEN의 번호 : [7289]\n",
      "END_TOKEN의 번호 : [7290]\n"
     ]
    }
   ],
   "source": [
    "print('START_TOKEN의 번호 :' ,[tokenizer.vocab_size])\n",
    "print('END_TOKEN의 번호 :' ,[tokenizer.vocab_size + 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9485e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7291\n"
     ]
    }
   ],
   "source": [
    "# 시작 토큰과 종료 토큰을 고려하여 +2를 하여 단어장의 크기를 산정합니다.\n",
    "VOCAB_SIZE = tokenizer.vocab_size + 2\n",
    "print(VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c74c0b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정수 인코딩 후의 21번째 질문 샘플: [4000, 264, 923, 3051]\n",
      "정수 인코딩 후의 21번째 답변 샘플: [379, 200, 168, 29, 1888, 336, 1]\n"
     ]
    }
   ],
   "source": [
    "# 임의의 22번째 샘플에 대해서 정수 인코딩 작업을 수행.\n",
    "# 각 토큰을 고유한 정수로 변환\n",
    "print('정수 인코딩 후의 21번째 질문 샘플: {}'.format(tokenizer.encode(questions[21])))\n",
    "print('정수 인코딩 후의 21번째 답변 샘플: {}'.format(tokenizer.encode(answers[21])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "38452b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    }
   ],
   "source": [
    "# 샘플의 최대 허용 길이 또는 패딩 후의 최종 길이\n",
    "MAX_LENGTH = 40\n",
    "print(MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a23bdf7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# 정수 인코딩, 최대 길이를 초과하는 샘플 제거, 패딩\n",
    "def tokenize_and_filter(inputs, outputs):\n",
    "  tokenized_inputs, tokenized_outputs = [], []\n",
    "  \n",
    "  for (sentence1, sentence2) in zip(inputs, outputs):\n",
    "    # 정수 인코딩 과정에서 시작 토큰과 종료 토큰을 추가\n",
    "    sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
    "    sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
    "\n",
    "    # 최대 길이 40 이하인 경우에만 데이터셋으로 허용\n",
    "    if len(sentence1) <= MAX_LENGTH and len(sentence2) <= MAX_LENGTH:\n",
    "      tokenized_inputs.append(sentence1)\n",
    "      tokenized_outputs.append(sentence2)\n",
    "  \n",
    "  # 최대 길이 40으로 모든 데이터셋을 패딩\n",
    "  tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n",
    "  tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\n",
    "  \n",
    "  return tokenized_inputs, tokenized_outputs\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb69772e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어장의 크기 : 7291\n",
      "필터링 후의 질문 샘플 개수: 11823\n",
      "필터링 후의 답변 샘플 개수: 11823\n"
     ]
    }
   ],
   "source": [
    "questions, answers = tokenize_and_filter(questions, answers)\n",
    "print('단어장의 크기 :',(VOCAB_SIZE))\n",
    "print('필터링 후의 질문 샘플 개수: {}'.format(len(questions)))\n",
    "print('필터링 후의 답변 샘플 개수: {}'.format(len(answers)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e389f5",
   "metadata": {},
   "source": [
    "### 교사강요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ec605f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 20000\n",
    "\n",
    "# 디코더는 이전의 target을 다음의 input으로 사용합니다.\n",
    "# 이에 따라 outputs에서는 START_TOKEN을 제거하겠습니다.\n",
    "dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {\n",
    "        'inputs': questions,\n",
    "        'dec_inputs': answers[:, :-1]\n",
    "    },\n",
    "    {\n",
    "        'outputs': answers[:, 1:]\n",
    "    },\n",
    "))\n",
    "\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42cf95c4",
   "metadata": {},
   "source": [
    "## Step 4. 모델 구성하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053b7666",
   "metadata": {},
   "source": [
    "위 실습 내용을 참고하여 트랜스포머 모델을 구현합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca65a21d",
   "metadata": {},
   "source": [
    "### 포지셔널 인코딩 레이어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "86337e84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# 포지셔널 인코딩 레이어\n",
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "\n",
    "  def __init__(self, position, d_model):\n",
    "    super(PositionalEncoding, self).__init__()\n",
    "    self.pos_encoding = self.positional_encoding(position, d_model)\n",
    "\n",
    "  def get_angles(self, position, i, d_model):\n",
    "    angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
    "    return position * angles\n",
    "\n",
    "  def positional_encoding(self, position, d_model):\n",
    "    # 각도 배열 생성\n",
    "    angle_rads = self.get_angles(\n",
    "        position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
    "        i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
    "        d_model=d_model)\n",
    "\n",
    "    # 배열의 짝수 인덱스에는 sin 함수 적용\n",
    "    sines = tf.math.sin(angle_rads[:, 0::2])\n",
    "    # 배열의 홀수 인덱스에는 cosine 함수 적용\n",
    "    cosines = tf.math.cos(angle_rads[:, 1::2])\n",
    "\n",
    "    # sin과 cosine이 교차되도록 재배열\n",
    "    pos_encoding = tf.stack([sines, cosines], axis=0)\n",
    "    pos_encoding = tf.transpose(pos_encoding,[1, 2, 0]) \n",
    "    pos_encoding = tf.reshape(pos_encoding, [position, d_model])\n",
    "\n",
    "    pos_encoding = pos_encoding[tf.newaxis, ...]\n",
    "    return tf.cast(pos_encoding, tf.float32)\n",
    "\n",
    "  def call(self, inputs):\n",
    "    return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]\n",
    "\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9448baff",
   "metadata": {},
   "source": [
    "### scaled_dot_product_attention 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a9e8e2d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# 스케일드 닷 프로덕트 어텐션 함수\n",
    "def scaled_dot_product_attention(query, key, value, mask):\n",
    "  # 어텐션 가중치는 Q와 K의 닷 프로덕트\n",
    "  matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
    "\n",
    "  # 가중치를 정규화\n",
    "  depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "  logits = matmul_qk / tf.math.sqrt(depth)\n",
    "\n",
    "  # 패딩에 마스크 추가\n",
    "  if mask is not None:\n",
    "    logits += (mask * -1e9)\n",
    "\n",
    "  # softmax적용\n",
    "  attention_weights = tf.nn.softmax(logits, axis=-1)\n",
    "\n",
    "  # 최종 어텐션은 가중치와 V의 닷 프로덕트\n",
    "  output = tf.matmul(attention_weights, value)\n",
    "  return output\n",
    "\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f9fa39",
   "metadata": {},
   "source": [
    "### MultiHeadAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7b9a6aa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "\n",
    "  def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
    "    super(MultiHeadAttention, self).__init__(name=name)\n",
    "    self.num_heads = num_heads\n",
    "    self.d_model = d_model\n",
    "\n",
    "    assert d_model % self.num_heads == 0\n",
    "\n",
    "    self.depth = d_model // self.num_heads\n",
    "\n",
    "    self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
    "    self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
    "    self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "    self.dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "  def split_heads(self, inputs, batch_size):\n",
    "    inputs = tf.reshape(\n",
    "        inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
    "    return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
    "\n",
    "  def call(self, inputs):\n",
    "    query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
    "        'value'], inputs['mask']\n",
    "    batch_size = tf.shape(query)[0]\n",
    "\n",
    "    # Q, K, V에 각각 Dense를 적용합니다\n",
    "    query = self.query_dense(query)\n",
    "    key = self.key_dense(key)\n",
    "    value = self.value_dense(value)\n",
    "\n",
    "    # 병렬 연산을 위한 머리를 여러 개 만듭니다\n",
    "    query = self.split_heads(query, batch_size)\n",
    "    key = self.split_heads(key, batch_size)\n",
    "    value = self.split_heads(value, batch_size)\n",
    "\n",
    "    # 스케일드 닷 프로덕트 어텐션 함수\n",
    "    scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
    "\n",
    "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "\n",
    "    # 어텐션 연산 후에 각 결과를 다시 연결(concatenate)합니다\n",
    "    concat_attention = tf.reshape(scaled_attention,\n",
    "                                  (batch_size, -1, self.d_model))\n",
    "\n",
    "    # 최종 결과에도 Dense를 한 번 더 적용합니다\n",
    "    outputs = self.dense(concat_attention)\n",
    "\n",
    "    return outputs\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86faaf7f",
   "metadata": {},
   "source": [
    "### 패딩 마스크"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "158cebb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def create_padding_mask(x):\n",
    "  mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
    "  # (batch_size, 1, 1, sequence length)\n",
    "  return mask[:, tf.newaxis, tf.newaxis, :]\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5119da",
   "metadata": {},
   "source": [
    "### look_ahead_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "25e6a087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def create_look_ahead_mask(x):\n",
    "  seq_len = tf.shape(x)[1]\n",
    "  look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
    "  padding_mask = create_padding_mask(x)\n",
    "  return tf.maximum(look_ahead_mask, padding_mask)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bda772b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# 인코더 하나의 레이어를 함수로 구현.\n",
    "# 이 하나의 레이어 안에는 두 개의 서브 레이어가 존재합니다.\n",
    "def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
    "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "\n",
    "  # 패딩 마스크 사용\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "  # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "  attention = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention\")({\n",
    "          'query': inputs,\n",
    "          'key': inputs,\n",
    "          'value': inputs,\n",
    "          'mask': padding_mask\n",
    "      })\n",
    "\n",
    "  # 어텐션의 결과는 Dropout과 Layer Normalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
    "  attention = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(inputs + attention)\n",
    "\n",
    "  # 두 번째 서브 레이어 : 2개의 완전연결층\n",
    "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
    "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "  # 완전연결층의 결과는 Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "  outputs = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention + outputs)\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, padding_mask], outputs=outputs, name=name)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3e342bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def encoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name=\"encoder\"):\n",
    "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "\n",
    "  # 패딩 마스크 사용\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "  # 임베딩 레이어\n",
    "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "  # 포지셔널 인코딩\n",
    "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "  # num_layers만큼 쌓아올린 인코더의 층.\n",
    "  for i in range(num_layers):\n",
    "    outputs = encoder_layer(\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "        name=\"encoder_layer_{}\".format(i),\n",
    "    )([outputs, padding_mask])\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, padding_mask], outputs=outputs, name=name)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "240f3584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# 디코더 하나의 레이어를 함수로 구현.\n",
    "# 이 하나의 레이어 안에는 세 개의 서브 레이어가 존재합니다.\n",
    "def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
    "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "  enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
    "  look_ahead_mask = tf.keras.Input(\n",
    "      shape=(1, None, None), name=\"look_ahead_mask\")\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "  # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "  attention1 = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention_1\")(inputs={\n",
    "          'query': inputs,\n",
    "          'key': inputs,\n",
    "          'value': inputs,\n",
    "          'mask': look_ahead_mask\n",
    "      })\n",
    "\n",
    "  # 멀티 헤드 어텐션의 결과는 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  attention1 = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention1 + inputs)\n",
    "\n",
    "  # 두 번째 서브 레이어 : 마스크드 멀티 헤드 어텐션 수행 (인코더-디코더 어텐션)\n",
    "  attention2 = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention_2\")(inputs={\n",
    "          'query': attention1,\n",
    "          'key': enc_outputs,\n",
    "          'value': enc_outputs,\n",
    "          'mask': padding_mask\n",
    "      })\n",
    "\n",
    "  # 마스크드 멀티 헤드 어텐션의 결과는\n",
    "  # Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
    "  attention2 = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention2 + attention1)\n",
    "\n",
    "  # 세 번째 서브 레이어 : 2개의 완전연결층\n",
    "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention2)\n",
    "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "  # 완전연결층의 결과는 Dropout과 LayerNormalization 수행\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "  outputs = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(outputs + attention2)\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "      outputs=outputs,\n",
    "      name=name)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5a9c23fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def decoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name='decoder'):\n",
    "  inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
    "  enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
    "  look_ahead_mask = tf.keras.Input(\n",
    "      shape=(1, None, None), name='look_ahead_mask')\n",
    "\n",
    "  # 패딩 마스크\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "  \n",
    "  # 임베딩 레이어\n",
    "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "  # 포지셔널 인코딩\n",
    "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "  # Dropout이라는 훈련을 돕는 테크닉을 수행\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "  for i in range(num_layers):\n",
    "    outputs = decoder_layer(\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "        name='decoder_layer_{}'.format(i),\n",
    "    )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "      outputs=outputs,\n",
    "      name=name)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666aed2d",
   "metadata": {},
   "source": [
    "### Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cae6570f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def transformer(vocab_size,\n",
    "                num_layers,\n",
    "                units,\n",
    "                d_model,\n",
    "                num_heads,\n",
    "                dropout,\n",
    "                name=\"transformer\"):\n",
    "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "  dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
    "\n",
    "  # 인코더에서 패딩을 위한 마스크\n",
    "  enc_padding_mask = tf.keras.layers.Lambda(\n",
    "      create_padding_mask, output_shape=(1, 1, None),\n",
    "      name='enc_padding_mask')(inputs)\n",
    "\n",
    "  # 디코더에서 미래의 토큰을 마스크 하기 위해서 사용합니다.\n",
    "  # 내부적으로 패딩 마스크도 포함되어져 있습니다.\n",
    "  look_ahead_mask = tf.keras.layers.Lambda(\n",
    "      create_look_ahead_mask,\n",
    "      output_shape=(1, None, None),\n",
    "      name='look_ahead_mask')(dec_inputs)\n",
    "\n",
    "  # 두 번째 어텐션 블록에서 인코더의 벡터들을 마스킹\n",
    "  # 디코더에서 패딩을 위한 마스크\n",
    "  dec_padding_mask = tf.keras.layers.Lambda(\n",
    "      create_padding_mask, output_shape=(1, 1, None),\n",
    "      name='dec_padding_mask')(inputs)\n",
    "\n",
    "  # 인코더\n",
    "  enc_outputs = encoder(\n",
    "      vocab_size=vocab_size,\n",
    "      num_layers=num_layers,\n",
    "      units=units,\n",
    "      d_model=d_model,\n",
    "      num_heads=num_heads,\n",
    "      dropout=dropout,\n",
    "  )(inputs=[inputs, enc_padding_mask])\n",
    "\n",
    "  # 디코더\n",
    "  dec_outputs = decoder(\n",
    "      vocab_size=vocab_size,\n",
    "      num_layers=num_layers,\n",
    "      units=units,\n",
    "      d_model=d_model,\n",
    "      num_heads=num_heads,\n",
    "      dropout=dropout,\n",
    "  )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
    "\n",
    "  # 완전연결층\n",
    "  outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
    "\n",
    "  return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c81756ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputs (InputLayer)             [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dec_inputs (InputLayer)         [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Functional)            (None, None, 512)    6888960     inputs[0][0]                     \n",
      "                                                                 enc_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "look_ahead_mask (Lambda)        (None, 1, None, None 0           dec_inputs[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dec_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Functional)            (None, None, 512)    8992256     dec_inputs[0][0]                 \n",
      "                                                                 encoder[0][0]                    \n",
      "                                                                 look_ahead_mask[0][0]            \n",
      "                                                                 dec_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "outputs (Dense)                 (None, None, 7291)   3740283     decoder[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 19,621,499\n",
      "Trainable params: 19,621,499\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# 하이퍼파라미터\n",
    "NUM_LAYERS = 2 # 인코더와 디코더의 층의 개수\n",
    "D_MODEL = 512 # 인코더와 디코더 내부의 입, 출력의 고정 차원\n",
    "NUM_HEADS = 8 # 멀티 헤드 어텐션에서의 헤드 수 \n",
    "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기\n",
    "DROPOUT = 0.1 # 드롭아웃의 비율\n",
    "\n",
    "model = transformer(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    units=UNITS,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742937fe",
   "metadata": {},
   "source": [
    "### 손실함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "137fa014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def loss_function(y_true, y_pred):\n",
    "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "  \n",
    "  loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "      from_logits=True, reduction='none')(y_true, y_pred)\n",
    "\n",
    "  mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
    "  loss = tf.multiply(loss, mask)\n",
    "\n",
    "  return tf.reduce_mean(loss)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8880a8fc",
   "metadata": {},
   "source": [
    "### 커스텀 학습률"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e4d56457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "\n",
    "  def __init__(self, d_model, warmup_steps=4000):\n",
    "    super(CustomSchedule, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "    self.warmup_steps = warmup_steps\n",
    "\n",
    "  def __call__(self, step):\n",
    "    arg1 = tf.math.rsqrt(step)\n",
    "    arg2 = step * (self.warmup_steps**-1.5)\n",
    "\n",
    "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f4faad57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "learning_rate = CustomSchedule(D_MODEL)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ecc56c62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "185/185 [==============================] - 24s 84ms/step - loss: 1.5589 - accuracy: 0.0309\n",
      "Epoch 2/50\n",
      "185/185 [==============================] - 16s 84ms/step - loss: 1.1522 - accuracy: 0.0514\n",
      "Epoch 3/50\n",
      "185/185 [==============================] - 16s 87ms/step - loss: 1.0085 - accuracy: 0.0606\n",
      "Epoch 4/50\n",
      "185/185 [==============================] - 16s 86ms/step - loss: 0.9098 - accuracy: 0.0696\n",
      "Epoch 5/50\n",
      "185/185 [==============================] - 16s 87ms/step - loss: 0.8215 - accuracy: 0.0772\n",
      "Epoch 6/50\n",
      "185/185 [==============================] - 16s 87ms/step - loss: 0.7384 - accuracy: 0.0849\n",
      "Epoch 7/50\n",
      "185/185 [==============================] - 16s 88ms/step - loss: 0.6563 - accuracy: 0.0938\n",
      "Epoch 8/50\n",
      "185/185 [==============================] - 16s 88ms/step - loss: 0.5711 - accuracy: 0.1047\n",
      "Epoch 9/50\n",
      "185/185 [==============================] - 16s 88ms/step - loss: 0.4835 - accuracy: 0.1167\n",
      "Epoch 10/50\n",
      "185/185 [==============================] - 16s 89ms/step - loss: 0.3964 - accuracy: 0.1294\n",
      "Epoch 11/50\n",
      "185/185 [==============================] - 16s 89ms/step - loss: 0.3140 - accuracy: 0.1429\n",
      "Epoch 12/50\n",
      "185/185 [==============================] - 17s 89ms/step - loss: 0.2387 - accuracy: 0.1554\n",
      "Epoch 13/50\n",
      "185/185 [==============================] - 17s 90ms/step - loss: 0.1778 - accuracy: 0.1658\n",
      "Epoch 14/50\n",
      "185/185 [==============================] - 17s 90ms/step - loss: 0.1304 - accuracy: 0.1746\n",
      "Epoch 15/50\n",
      "185/185 [==============================] - 17s 90ms/step - loss: 0.0972 - accuracy: 0.1811\n",
      "Epoch 16/50\n",
      "185/185 [==============================] - 17s 90ms/step - loss: 0.0752 - accuracy: 0.1849\n",
      "Epoch 17/50\n",
      "185/185 [==============================] - 17s 91ms/step - loss: 0.0637 - accuracy: 0.1868\n",
      "Epoch 18/50\n",
      "185/185 [==============================] - 17s 90ms/step - loss: 0.0596 - accuracy: 0.1871\n",
      "Epoch 19/50\n",
      "185/185 [==============================] - 17s 91ms/step - loss: 0.0548 - accuracy: 0.1880\n",
      "Epoch 20/50\n",
      "185/185 [==============================] - 17s 91ms/step - loss: 0.0544 - accuracy: 0.1880\n",
      "Epoch 21/50\n",
      "185/185 [==============================] - 17s 91ms/step - loss: 0.0545 - accuracy: 0.1877\n",
      "Epoch 22/50\n",
      "185/185 [==============================] - 17s 91ms/step - loss: 0.0529 - accuracy: 0.1882\n",
      "Epoch 23/50\n",
      "185/185 [==============================] - 17s 91ms/step - loss: 0.0489 - accuracy: 0.1890\n",
      "Epoch 24/50\n",
      "185/185 [==============================] - 17s 91ms/step - loss: 0.0442 - accuracy: 0.1901\n",
      "Epoch 25/50\n",
      "185/185 [==============================] - 17s 91ms/step - loss: 0.0396 - accuracy: 0.1914\n",
      "Epoch 26/50\n",
      "185/185 [==============================] - 17s 91ms/step - loss: 0.0366 - accuracy: 0.1921\n",
      "Epoch 27/50\n",
      "185/185 [==============================] - 17s 91ms/step - loss: 0.0332 - accuracy: 0.1930\n",
      "Epoch 28/50\n",
      "185/185 [==============================] - 17s 91ms/step - loss: 0.0303 - accuracy: 0.1938\n",
      "Epoch 29/50\n",
      "185/185 [==============================] - 17s 91ms/step - loss: 0.0277 - accuracy: 0.1945\n",
      "Epoch 30/50\n",
      "185/185 [==============================] - 17s 91ms/step - loss: 0.0259 - accuracy: 0.1950\n",
      "Epoch 31/50\n",
      "185/185 [==============================] - 17s 91ms/step - loss: 0.0239 - accuracy: 0.1954\n",
      "Epoch 32/50\n",
      "185/185 [==============================] - 17s 91ms/step - loss: 0.0222 - accuracy: 0.1960\n",
      "Epoch 33/50\n",
      "185/185 [==============================] - 17s 91ms/step - loss: 0.0209 - accuracy: 0.1963\n",
      "Epoch 34/50\n",
      "185/185 [==============================] - 17s 91ms/step - loss: 0.0200 - accuracy: 0.1965\n",
      "Epoch 35/50\n",
      "185/185 [==============================] - 17s 91ms/step - loss: 0.0189 - accuracy: 0.1968\n",
      "Epoch 36/50\n",
      "185/185 [==============================] - 17s 91ms/step - loss: 0.0175 - accuracy: 0.1973\n",
      "Epoch 37/50\n",
      "185/185 [==============================] - 17s 91ms/step - loss: 0.0164 - accuracy: 0.1976\n",
      "Epoch 38/50\n",
      "185/185 [==============================] - 17s 91ms/step - loss: 0.0157 - accuracy: 0.1977\n",
      "Epoch 39/50\n",
      "185/185 [==============================] - 17s 91ms/step - loss: 0.0144 - accuracy: 0.1981\n",
      "Epoch 40/50\n",
      "185/185 [==============================] - 17s 91ms/step - loss: 0.0134 - accuracy: 0.1984\n",
      "Epoch 41/50\n",
      "185/185 [==============================] - 17s 91ms/step - loss: 0.0135 - accuracy: 0.1983\n",
      "Epoch 42/50\n",
      "185/185 [==============================] - 17s 91ms/step - loss: 0.0132 - accuracy: 0.1983\n",
      "Epoch 43/50\n",
      "185/185 [==============================] - 17s 91ms/step - loss: 0.0125 - accuracy: 0.1986\n",
      "Epoch 44/50\n",
      "185/185 [==============================] - 17s 91ms/step - loss: 0.0117 - accuracy: 0.1988\n",
      "Epoch 45/50\n",
      "185/185 [==============================] - 17s 91ms/step - loss: 0.0115 - accuracy: 0.1989\n",
      "Epoch 46/50\n",
      "185/185 [==============================] - 17s 91ms/step - loss: 0.0113 - accuracy: 0.1989\n",
      "Epoch 47/50\n",
      "185/185 [==============================] - 17s 91ms/step - loss: 0.0107 - accuracy: 0.1990\n",
      "Epoch 48/50\n",
      "185/185 [==============================] - 17s 91ms/step - loss: 0.0103 - accuracy: 0.1992\n",
      "Epoch 49/50\n",
      "185/185 [==============================] - 17s 91ms/step - loss: 0.0100 - accuracy: 0.1993\n",
      "Epoch 50/50\n",
      "185/185 [==============================] - 17s 91ms/step - loss: 0.0092 - accuracy: 0.1994\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fdbd946ef70>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPOCHS = 50\n",
    "model.fit(dataset, epochs=EPOCHS, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1151b0a",
   "metadata": {},
   "source": [
    "## Step 4. 모델 평가하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c654211",
   "metadata": {},
   "source": [
    "Step 2에서 선택한 전처리 방법을 고려하여 입력된 문장에 대해서 대답을 얻는 예측 함수를 만듭니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f249b7",
   "metadata": {},
   "source": [
    "### Step 2 에서 사용한 SOYNLP 사용. 출처:https://wikidocs.net/92961"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "576c43f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(sentence):\n",
    "    tokenizer = Okt()\n",
    "    stc = tokenizer.morphs(sentence)\n",
    "    \n",
    "    temp = \"\"\n",
    "    for i in range(len(stc)-1):\n",
    "        temp += stc[i] + \" \"\n",
    "    \n",
    "    temp += stc[-1]\n",
    "    \n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "effef698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def decoder_inference(sentence):\n",
    "  sentence = preprocess_sentence(sentence)\n",
    "\n",
    "  # 입력된 문장을 정수 인코딩 후, 시작 토큰과 종료 토큰을 앞뒤로 추가.\n",
    "  # ex) Where have you been? → [[8331   86   30    5 1059    7 8332]]\n",
    "  sentence = tf.expand_dims(\n",
    "      START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
    "\n",
    "  # 디코더의 현재까지의 예측한 출력 시퀀스가 지속적으로 저장되는 변수.\n",
    "  # 처음에는 예측한 내용이 없음으로 시작 토큰만 별도 저장. ex) 8331\n",
    "  output_sequence = tf.expand_dims(START_TOKEN, 0)\n",
    "\n",
    "  # 디코더의 인퍼런스 단계\n",
    "  for i in range(MAX_LENGTH):\n",
    "    # 디코더는 최대 MAX_LENGTH의 길이만큼 다음 단어 예측을 반복합니다.\n",
    "    predictions = model(inputs=[sentence, output_sequence], training=False)\n",
    "    predictions = predictions[:, -1:, :]\n",
    "\n",
    "    # 현재 예측한 단어의 정수\n",
    "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "\n",
    "    # 만약 현재 예측한 단어가 종료 토큰이라면 for문을 종료\n",
    "    if tf.equal(predicted_id, END_TOKEN[0]):\n",
    "      break\n",
    "\n",
    "    # 예측한 단어들은 지속적으로 output_sequence에 추가됩니다.\n",
    "    # 이 output_sequence는 다시 디코더의 입력이 됩니다.\n",
    "    output_sequence = tf.concat([output_sequence, predicted_id], axis=-1)\n",
    "\n",
    "  return tf.squeeze(output_sequence, axis=0)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef1c37d",
   "metadata": {},
   "source": [
    "### 띄어쓰기 잘 하기 추가. 출처: https://wikidocs.net/92961"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9c38ee66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/haven-jeon/PyKoSpacing.git\n",
      "  Cloning https://github.com/haven-jeon/PyKoSpacing.git to /tmp/pip-req-build-7hqws08x\n",
      "  Running command git clone --filter=blob:none -q https://github.com/haven-jeon/PyKoSpacing.git /tmp/pip-req-build-7hqws08x\n",
      "  Resolved https://github.com/haven-jeon/PyKoSpacing.git to commit d8f2b1cb9c904e5a6a181bbf6aeee44fc6e9eab1\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting tensorflow==2.5.3\n",
      "  Downloading tensorflow-2.5.3-cp39-cp39-manylinux2010_x86_64.whl (460.4 MB)\n",
      "     |████████████████████████████████| 460.4 MB 10 kB/s               �███████████▋  | 426.2 MB 151.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: h5py==3.1.0 in /opt/conda/lib/python3.9/site-packages (from pykospacing==0.5) (3.1.0)\n",
      "Collecting argparse>=1.4.0\n",
      "  Downloading argparse-1.4.0-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: numpy>=1.19.3 in /opt/conda/lib/python3.9/site-packages (from h5py==3.1.0->pykospacing==0.5) (1.21.4)\n",
      "Requirement already satisfied: wheel~=0.35 in /opt/conda/lib/python3.9/site-packages (from tensorflow==2.5.3->pykospacing==0.5) (0.37.0)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in /opt/conda/lib/python3.9/site-packages (from tensorflow==2.5.3->pykospacing==0.5) (1.1.2)\n",
      "Collecting numpy>=1.19.3\n",
      "  Downloading numpy-1.19.5-cp39-cp39-manylinux2010_x86_64.whl (14.9 MB)\n",
      "     |████████████████████████████████| 14.9 MB 117.1 MB/s            \n",
      "\u001b[?25hCollecting typing-extensions~=3.7.4\n",
      "  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in /opt/conda/lib/python3.9/site-packages (from tensorflow==2.5.3->pykospacing==0.5) (1.1.0)\n",
      "Requirement already satisfied: gast==0.4.0 in /opt/conda/lib/python3.9/site-packages (from tensorflow==2.5.3->pykospacing==0.5) (0.4.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /opt/conda/lib/python3.9/site-packages (from tensorflow==2.5.3->pykospacing==0.5) (3.19.1)\n",
      "Requirement already satisfied: absl-py~=0.10 in /opt/conda/lib/python3.9/site-packages (from tensorflow==2.5.3->pykospacing==0.5) (0.12.0)\n",
      "Collecting tensorflow-estimator<2.6.0,>=2.5.0\n",
      "  Downloading tensorflow_estimator-2.5.0-py2.py3-none-any.whl (462 kB)\n",
      "     |████████████████████████████████| 462 kB 79.9 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: opt-einsum~=3.3.0 in /opt/conda/lib/python3.9/site-packages (from tensorflow==2.5.3->pykospacing==0.5) (3.3.0)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in /opt/conda/lib/python3.9/site-packages (from tensorflow==2.5.3->pykospacing==0.5) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in /opt/conda/lib/python3.9/site-packages (from tensorflow==2.5.3->pykospacing==0.5) (1.12)\n",
      "Collecting keras-nightly~=2.5.0.dev\n",
      "  Downloading keras_nightly-2.5.0.dev2021032900-py2.py3-none-any.whl (1.2 MB)\n",
      "     |████████████████████████████████| 1.2 MB 61.3 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: google-pasta~=0.2 in /opt/conda/lib/python3.9/site-packages (from tensorflow==2.5.3->pykospacing==0.5) (0.2.0)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /opt/conda/lib/python3.9/site-packages (from tensorflow==2.5.3->pykospacing==0.5) (1.12.1)\n",
      "Requirement already satisfied: tensorboard~=2.5 in /opt/conda/lib/python3.9/site-packages (from tensorflow==2.5.3->pykospacing==0.5) (2.7.0)\n",
      "Collecting grpcio~=1.34.0\n",
      "  Downloading grpcio-1.34.1-cp39-cp39-manylinux2014_x86_64.whl (4.0 MB)\n",
      "     |████████████████████████████████| 4.0 MB 98.6 MB/s            \n",
      "\u001b[?25hCollecting six~=1.15.0\n",
      "  Downloading six-1.15.0-py2.py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.9/site-packages (from tensorboard~=2.5->tensorflow==2.5.3->pykospacing==0.5) (2.0.2)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.9/site-packages (from tensorboard~=2.5->tensorflow==2.5.3->pykospacing==0.5) (1.8.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.9/site-packages (from tensorboard~=2.5->tensorflow==2.5.3->pykospacing==0.5) (2.26.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.9/site-packages (from tensorboard~=2.5->tensorflow==2.5.3->pykospacing==0.5) (0.6.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.9/site-packages (from tensorboard~=2.5->tensorflow==2.5.3->pykospacing==0.5) (3.3.6)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.9/site-packages (from tensorboard~=2.5->tensorflow==2.5.3->pykospacing==0.5) (59.4.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.9/site-packages (from tensorboard~=2.5->tensorflow==2.5.3->pykospacing==0.5) (2.3.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.9/site-packages (from tensorboard~=2.5->tensorflow==2.5.3->pykospacing==0.5) (0.4.6)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.3->pykospacing==0.5) (4.2.4)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.3->pykospacing==0.5) (4.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.3->pykospacing==0.5) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.9/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow==2.5.3->pykospacing==0.5) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow==2.5.3->pykospacing==0.5) (4.8.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.3->pykospacing==0.5) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.3->pykospacing==0.5) (2.10)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.3->pykospacing==0.5) (2.0.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.3->pykospacing==0.5) (1.26.7)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.5->tensorflow==2.5.3->pykospacing==0.5) (3.6.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.3->pykospacing==0.5) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow==2.5.3->pykospacing==0.5) (3.1.1)\n",
      "Building wheels for collected packages: pykospacing\n",
      "  Building wheel for pykospacing (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pykospacing: filename=pykospacing-0.5-py3-none-any.whl size=2268397 sha256=45d938119e7c5d13f31a35ef67437d658731037b75290e9f5ecf35a98a736174\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-p1d7jahn/wheels/ca/f2/8d/94e29f54f44b61ffe18da21ed0199d43042bd1350f44107517\n",
      "Successfully built pykospacing\n",
      "Installing collected packages: six, numpy, grpcio, typing-extensions, tensorflow-estimator, keras-nightly, tensorflow, argparse, pykospacing\n",
      "  Attempting uninstall: six\n",
      "    Found existing installation: six 1.16.0\n",
      "    Uninstalling six-1.16.0:\n",
      "      Successfully uninstalled six-1.16.0\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.21.4\n",
      "    Uninstalling numpy-1.21.4:\n",
      "      Successfully uninstalled numpy-1.21.4\n",
      "  Attempting uninstall: grpcio\n",
      "    Found existing installation: grpcio 1.42.0\n",
      "    Uninstalling grpcio-1.42.0:\n",
      "      Successfully uninstalled grpcio-1.42.0\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing-extensions 4.0.1\n",
      "    Uninstalling typing-extensions-4.0.1:\n",
      "      Successfully uninstalled typing-extensions-4.0.1\n",
      "  Attempting uninstall: tensorflow-estimator\n",
      "    Found existing installation: tensorflow-estimator 2.7.0\n",
      "    Uninstalling tensorflow-estimator-2.7.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.7.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-gpu 2.6.0 requires grpcio<2.0,>=1.37.0, but you have grpcio 1.34.1 which is incompatible.\n",
      "tensorflow-gpu 2.6.0 requires tensorflow-estimator~=2.6, but you have tensorflow-estimator 2.5.0 which is incompatible.\n",
      "grpcio-status 1.42.0 requires grpcio>=1.42.0, but you have grpcio 1.34.1 which is incompatible.\n",
      "black 21.12b0 requires typing-extensions>=3.10.0.0, but you have typing-extensions 3.7.4.3 which is incompatible.\u001b[0m\n",
      "Successfully installed argparse-1.4.0 grpcio-1.34.1 keras-nightly-2.5.0.dev2021032900 numpy-1.21.2 pykospacing-0.5 six-1.15.0 tensorflow-2.5.3 tensorflow-estimator-2.5.0 typing-extensions-3.7.4.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install git+https://github.com/haven-jeon/PyKoSpacing.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8fd2d2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pykospacing import Spacing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c9bfc195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def sentence_generation(sentence):\n",
    "  # 입력 문장에 대해서 디코더를 동작 시켜 예측된 정수 시퀀스를 리턴받습니다.\n",
    "  prediction = decoder_inference(sentence)\n",
    "\n",
    "  # 정수 시퀀스를 다시 텍스트 시퀀스로 변환합니다.\n",
    "  predicted_sentence = tokenizer.decode(\n",
    "      [i for i in prediction if i < tokenizer.vocab_size])\n",
    "  \n",
    "  predicted_sentence = predicted_sentence.replace(\" \",'') # 띄어쓰기 없애기\n",
    "  spacing = Spacing()\n",
    "  predicted_sentence = spacing(predicted_sentence)\n",
    "\n",
    "  print('입력 : {}'.format(sentence))\n",
    "  print('출력 : {}'.format(predicted_sentence))\n",
    "\n",
    "  return predicted_sentence\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a2c7dbd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력: 안녕\n",
      "입력 : 안녕\n",
      "출력 : 안녕하세요.\n",
      "\n",
      "입력: 날 응원해줘\n",
      "입력 : 날 응원해줘\n",
      "출력 : 저도 같이 응원할게요.\n",
      "\n",
      "입력: 고마워\n",
      "입력 : 고마워\n",
      "출력 : 감사합니다.\n",
      "\n",
      "입력: 너는 누구야?\n",
      "입력 : 너는 누구야?\n",
      "출력 : 저는 마음을 이어주는 위로 봇입니다.\n",
      "\n",
      "입력: 졸려\n",
      "입력 : 졸려\n",
      "출력 : 오늘 일찍 주무세요.\n",
      "\n",
      "입력: 그래야지.. 잘자\n",
      "입력 : 그래야지.. 잘자\n",
      "출력 : 잠깐 쉬어가도 괜찮아요.\n",
      "\n",
      "입력: 그래 다음에 또 보자.\n",
      "입력 : 그래 다음에 또 보자.\n",
      "출력 : 괜찮은 척 하는 걸 수도 있어요.\n",
      "\n",
      "입력: 잘있어\n",
      "입력 : 잘있어\n",
      "출력 : 잘 살고 있을 거예요.\n",
      "\n",
      "입력:  \n",
      "대화 끝.\n"
     ]
    }
   ],
   "source": [
    "stc = \"\"\n",
    "while stc != \" \":\n",
    "    stc = str(input(\"입력: \"))\n",
    "    if stc == \" \":\n",
    "        print(\"대화 끝.\")\n",
    "        break\n",
    "    else:\n",
    "        sentence_generation(stc)\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b0370a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d1ecaba0",
   "metadata": {},
   "source": [
    "# 회고\n",
    "\n",
    "## 이번 프로젝트에서 어려웠던 점.\n",
    "#### 우선, 전처리 영역이 가장 어려웠습니다.\n",
    "- 영어 전처리는 어느정도 이해가 되었는데, 한글 전처리 영역은 매우 어려웠습니다. 어떤 부분에서 어떻게 끊어야 하는지도 어려웠지만, 영어의 경우 a-z같은 부분을 한글에서는 파이썬에서 어떻게 표현해야하는가에 대해 어려웠습니다. 띄어쓰기도 영어처럼 단어 별로 끊지 않고, 상황별로 띄어쓰기의 방법이 매우 달랐기 때문에, 이것을 어떻게 처리를 해 주어야 하는가에 대해 정말 많은 골 머리를 앓았습니다. 그러던 중 괜찮은 라이브러리를 찾게되었고, 사실 라이브러리 참고 없이 혼자 함수를 만들어 내어 하려다가, 결국 역시 만들어진 라이브러리가 최고다 라는 생각에 응용하게 되었는데, 생각보다 매우 만족스러운 결과를 얻게되어, 나중에 띄어쓰기 부분까지 참고하여 추가하였습니다.\n",
    "\n",
    "#### 다음으로는, 내용적인 부분이 어려웠습니다.\n",
    "- 이전에, 네이버 영화 리뷰와는 다르게, 멀티헤드, 스케일드 닷 프로덕트, 트랜스포머 등 새로이 배운 영역이 추가 되었는데, 이론적으로 완벽하게 이해하기는 어려웠습니다. 하지만 저의 챗 봇이 생각보다 매우 괜찮은 결과를 보여주었기에, 앞으로도 관련된 영역이 있다면, 다시 돌아와 틈틈히 보고 잘 이해하고 넘어 갈 예정입니다.\n",
    "\n",
    "## 프로젝트를 진행하면서 알아낸 점 혹은 아직 모호한 점.\n",
    "- 알아낸 점으로는, 한국어 전처리 관련 라이브러리에 대해 알게 된 점이 제가 전처리 부분에서 고민했던 만큼 제게 가장 큰 수익이었던것 같습니다. 좀 더 깊게 공부하게 되었을 때에는, 전처리 함수까지 혼자서 구현하고 싶지만, 역시 한글 관련해서 공부하신 학자들과 프로그래머들이 만들어 주신 라이브러리는 훌륭하다는 것을 깨달았습니다. 위의 라이브러리 덕에 아주 매끄러운 채팅 봇을 만들어 낸 것 같아 매우 기쁩니다.\n",
    "- 하지만 위에 설명 드렸듯, 이번 단원에서 새로이나온 멀티헤드, 스케일드 닷 프로덕트, 트랜스포머, 혹은 패딩 마스크, 더 나아가 커스텀 학습률 등에 대한 이론적인 부분을 잘 캐치하지 못하였기 때문에, 향후에 계속해서 공부해 나갈 예정입니다. 이런 함수를 이곳에서 배울 수 있게 되어 덕분에 좋은 결과를 낸 것 같아 참으로 기쁩니다.\n",
    "\n",
    "## 루브릭 평가 지표를 맞추기 위해 시도한 것들.\n",
    "#### 공백과 특수문자 처리, 토크나이징, 병렬 데이터 구축의 과정이 적절히 진행되었다.\n",
    "- 사실 제가 직접 디테일하게 구분한 것은 없지만, 맞추기 위해 매우 고심하였고, 끝끝내 좋은 적절한 라이브러리를 찾게 되었습니다.\n",
    "\n",
    "#### 구현한 트랜스포머 모델이 한국어 병렬 데이터 학습시 안정적으로 수렴하였다.\n",
    "- 위의 모호한 점에, 이론적으로 파악하지 못하였다고 설명했는데, 병렬적 이라는 단어는 알지만, 병렬 데이터 라는 개념에 대해 잘 이해하지 못하였기 때문에 제가 구조적으로 잘 만들어 낸 부분은 자신이 없습니다. 하지만, 학습이 안정적으로 되었기 때문에, 봇이 적절한 대화를 주고 받았다고 생각합니다.\n",
    "\n",
    "#### 한국어 입력문장에 그럴듯한 한국어로 답변을 리턴하였다.\n",
    "- 정말 신기할 정도였습니다. 제가 인터넷에서 돌아다니는 채팅봇과 대화를 하는 기분이었습니다. 그 기분을 여기 Jupyter notebook 환경에서 대화를 하고 있으니, 정말 제가 처음으로 저의 첫 인공지능 로봇을 만들어 낸 듯한 흡사 그러한 기분을 들게끔 하여 애정이 많이 갑니다.\n",
    "\n",
    "## 루브릭 평가 지표를 달성하지 못했을 때, 이유에 관한 추정\n",
    "- 아무래도, 이론적으로 이해하지 못하였기 때문에, 실습 노드의 함수들을 모두 끌어다 사용하였고, 때문에 혹시나 구조적으로 바꿔주면 좀 더 좋은 결과나 좀 더 깔끔한 결과가 나오는지, 혹은 더 추가할 수 있는데 추가하지 못하였다던지 매끄럽지 못하다 던지에 대한 판단을 스스로 할 수가 없었습니다. 솔직하게 제가 심히 고민하고 해결한 부분은 전처리 부분이 전부이며, 나머지 부분은 이해하려 시도하였으나, 확실한 결과를 얻어내지 못하였기 때문에, 루브릭 지표를 달성하지 못하였다면 이부분이 아닐까 추정해 봅니다.\n",
    "\n",
    "## 자기 다짐\n",
    "- 비록 내용적인 부분에서 다소 답답함을 느끼고 결국 완전히 습득하지는 못한 채로 노드를 완성하였지만, 결과가 제 생각 이상으로 좋은 결과를 보여 주었기에, 스스로가 매우 뿌듯하여 자신감이 생기는 노드였습니다. 앞에 두,세개 전 노드들은, 거의 반성문을 쓰다 시피 매우 안좋은 마음으로 끝이 났는데, 그 때 느낀 다짐으로, 욕심내거나 완벽하게, 그리고 모든걸 알아내려고 하지말고, 지금 내가 할 수 있는 이 상황에서 최선을 다하고 단 하나만 얻어가도 기분좋게 얻어가자 라는 다짐 덕분인지는 모르겠지만, 이전 노드들에서 느낀점의 연장선으로, 이번 노드에도 얻은것이 많아 기쁩니다. 위에 언급하였듯, 아직 모호하고 이해하지 못한 부분이 대부분 이지만, 알아낸 부분도 많고 무엇보다 자신감을 얻었기에, 많이 배우고 가며, 앞으로 공부할 내용이 더 있다는 사실에도 기쁩니다. 계속해서 지금같은 마음가짐으로 열심히 하겠습니다.\n",
    "\n",
    "감사합니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
